{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Consulting Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary Customer Churn\n",
    "\n",
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites. They've noticed that they have quite a bit of churn in clients. They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager. Luckily they have some historical data, can you help them out? Create a classification algorithm that will help classify whether or not a customer churned. Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "    Name : Name of the latest contact at Company\n",
    "    Age: Customer Age\n",
    "    Total_Purchase: Total Ads Purchased\n",
    "    Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "    Years: Totaly Years as a customer\n",
    "    Num_sites: Number of websites that use the service.\n",
    "    Onboard_date: Date that the name of the latest contact was onboarded\n",
    "    Location: Client HQ Address\n",
    "    Company: Name of Client Company\n",
    "    \n",
    "Once you've created the model and evaluated it, test out the model on some new data (you can think of this almost like a hold-out set) that your client has provided, saved under new_customers.csv. The client wants to know which customers are most likely to churn given this data (they don't have the label yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init('/home/gkouskosv/spark-2.4.5-bin-hadoop2.6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('ConProj').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('customer_churn.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                900|\n",
      "|   mean|0.16666666666666666|\n",
      "| stddev| 0.3728852122772358|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Churn').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|            Location|\n",
      "+-------+--------------------+\n",
      "|  count|                 900|\n",
      "|   mean|                null|\n",
      "| stddev|                null|\n",
      "|    min|00103 Jeffrey Cre...|\n",
      "|    max|Unit 9800 Box 287...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Location').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with the company column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('Company').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       Company|count|\n",
      "+--------------+-----+\n",
      "|Anderson Group|    4|\n",
      "|  Williams PLC|    3|\n",
      "|    Wilson PLC|    3|\n",
      "|     Evans LLC|    2|\n",
      "|     Ortiz Ltd|    2|\n",
      "|     Gates Ltd|    2|\n",
      "|Smith and Sons|    2|\n",
      "|      Rice PLC|    2|\n",
      "|  Williams Ltd|    2|\n",
      "|Davis and Sons|    2|\n",
      "|     Smith Ltd|    2|\n",
      "|      King LLC|    2|\n",
      "|   Davis Group|    2|\n",
      "|     Smith Inc|    2|\n",
      "|    Nelson LLC|    2|\n",
      "|   Smith Group|    2|\n",
      "|      Webb PLC|    2|\n",
      "|      Wise Inc|    2|\n",
      "|  Williams LLC|    2|\n",
      "|     Jones LLC|    2|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "by_comp = data.groupBy('Company').count()\n",
    "by_comp.orderBy(by_comp['count'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the column 'Company', it is better to drop it than hold it. The amount of companies are 873, and each one are shown from 1 to 4 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Num_Sites|\n",
      "+---------+\n",
      "|      8.0|\n",
      "|      7.0|\n",
      "|      4.0|\n",
      "|     11.0|\n",
      "|     14.0|\n",
      "|      3.0|\n",
      "|     10.0|\n",
      "|     13.0|\n",
      "|      6.0|\n",
      "|      5.0|\n",
      "|      9.0|\n",
      "|     12.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Num_Sites').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with the location\n",
    "\n",
    "Let's find out if Location column is helpful enough to be in out logistic regression model. It is better to hold only the zipcode from the whole address.\n",
    "\n",
    "Some zip codes consist of 10 chars. We will hold only the first 5 chars for every zip code. We will achieve that with 2 ways:\n",
    "1. With a custom function which splits the zip code at '-' and drop the last chars and\n",
    "2. With the build in function of pyspark, the substr, which takes 2 arguments: The starting point and the last. The remaining string is droped. \n",
    "\n",
    "Then, we will join the two tables by a generated id, with the monotonically_increasing_id function and drop the temporary column 'id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Location='10265 Elizabeth Mission Barkerburgh, AK 89518'),\n",
       " Row(Location='6157 Frank Gardens Suite 019 Carloshaven, RI 17756'),\n",
       " Row(Location='1331 Keith Court Alyssahaven, DE 90114'),\n",
       " Row(Location='13120 Daniel Mount Angelabury, WY 30645-4695'),\n",
       " Row(Location='765 Tricia Row Karenshire, MH 71730'),\n",
       " Row(Location='6187 Olson Mountains East Vincentborough, PR 74359'),\n",
       " Row(Location='4846 Savannah Road West Justin, IA 87713-3460'),\n",
       " Row(Location='25271 Roy Expressway Suite 147 Brownport, FM 59852-6150'),\n",
       " Row(Location='3725 Caroline Stravenue South Christineview, MA 82059'),\n",
       " Row(Location='363 Sandra Lodge Suite 144 South Ann, WI 51655-7561'),\n",
       " Row(Location='Unit 8120 Box 9160 DPO AA 43432'),\n",
       " Row(Location='Unit 1895 Box 0949 DPO AA 40249'),\n",
       " Row(Location='897 Kelley Overpass Suite 349 West Rebekahport, AZ 44793'),\n",
       " Row(Location='11488 Weaver Cape Hernandezberg, WI 63417-8544'),\n",
       " Row(Location='1774 Peter Row Apt. 712 New Autumn, MT 18782')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('Location').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.sql.functions import split, monotonically_increasing_id, isnull, max, row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89518', '17756', '90114', '30645-4695', '71730']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code = [word[0][-1] for word in data.select(split('Location', ' ')).collect()]\n",
    "zip_code[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_minus(lst):\n",
    "    without_minus = []\n",
    "    for code in lst:\n",
    "        if '-' in code:\n",
    "            without_minus.append(code.split('-')[0])\n",
    "        else:\n",
    "            without_minus.append(code)\n",
    "    return without_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_minus_zip = del_minus(zip_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89518', '17756', '90114', '30645', '71730']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_minus_zip[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89518', '17756', '90114', '30645-4695', '71730']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|            Location|split(Location, ,)[1]|\n",
      "+--------------------+---------------------+\n",
      "|10265 Elizabeth M...|             AK 89518|\n",
      "|6157 Frank Garden...|             RI 17756|\n",
      "|1331 Keith Court ...|             DE 90114|\n",
      "|13120 Daniel Moun...|        WY 30645-4695|\n",
      "|765 Tricia Row Ka...|             MH 71730|\n",
      "|6187 Olson Mounta...|             PR 74359|\n",
      "|4846 Savannah Roa...|        IA 87713-3460|\n",
      "|25271 Roy Express...|        FM 59852-6150|\n",
      "|3725 Caroline Str...|             MA 82059|\n",
      "|363 Sandra Lodge ...|        WI 51655-7561|\n",
      "|Unit 8120 Box 916...|                 null|\n",
      "|Unit 1895 Box 094...|                 null|\n",
      "|897 Kelley Overpa...|             AZ 44793|\n",
      "|11488 Weaver Cape...|        WI 63417-8544|\n",
      "|1774 Peter Row Ap...|             MT 18782|\n",
      "|45408 David Path ...|        HI 54903-6698|\n",
      "|28216 Wright Moun...|        DE 40999-2369|\n",
      "|Unit 4948 Box 481...|                 null|\n",
      "|69203 Crosby Divi...|             CO 87064|\n",
      "|9569 Caldwell Cre...|             RI 30637|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Location', split('Location', ',')[1]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_minus_zip = spark.createDataFrame([(value,) for value in no_minus_zip], ['no_minus_zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_minus_zip['no_minus_zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89518'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89518',\n",
       " '17756',\n",
       " '90114',\n",
       " '30645-4695',\n",
       " '71730',\n",
       " '74359',\n",
       " '87713-3460',\n",
       " '59852-6150',\n",
       " '82059',\n",
       " '51655-7561']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = spark.createDataFrame([(value,) for value in zip_code], ['zip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = zip_code.withColumn('zip', zip_code['zip_code'].substr(1,5)).drop('zip_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = zip_code.withColumn('zip', zip_code['zip'].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(zip=89518, idx=1),\n",
       " Row(zip=17756, idx=2),\n",
       " Row(zip=90114, idx=3),\n",
       " Row(zip=30645, idx=4),\n",
       " Row(zip=71730, idx=5),\n",
       " Row(zip=74359, idx=6),\n",
       " Row(zip=87713, idx=7),\n",
       " Row(zip=59852, idx=8),\n",
       " Row(zip=82059, idx=9),\n",
       " Row(zip=51655, idx=10)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_code.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|               zip|               idx|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               900|               900|\n",
      "|   mean|50041.432222222225|             450.5|\n",
      "| stddev|28480.741571480794|259.95191863111916|\n",
      "|    min|               175|                 1|\n",
      "|    max|             99942|               900|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_code.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                900|\n",
      "|   mean|0.16666666666666666|\n",
      "| stddev| 0.3728852122772358|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Churn').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = zip_code.withColumn('idx', monotonically_increasing_id())\n",
    "data = data.withColumn('idx', monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(idx)|\n",
      "+--------+\n",
      "|     900|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_code.select(max('idx')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = W.orderBy('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code = zip_code.withColumn('idx', row_number().over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('idx', row_number().over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.join(zip_code, on='idx', how='inner').drop('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Names': 'Cameron Williams',\n",
       " 'Age': 42.0,\n",
       " 'Total_Purchase': 11066.8,\n",
       " 'Account_Manager': 0,\n",
       " 'Years': 7.22,\n",
       " 'Num_Sites': 8.0,\n",
       " 'Onboard_date': datetime.datetime(2013, 8, 30, 7, 0, 40),\n",
       " 'Location': '10265 Elizabeth Mission Barkerburgh, AK 89518',\n",
       " 'Company': 'Harvey LLC',\n",
       " 'Churn': 1,\n",
       " 'zip': 89518}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08592553706723392"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stat.corr('Churn', 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013873604684394627"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.stat.corr('Churn', 'zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's deal with the on board date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
